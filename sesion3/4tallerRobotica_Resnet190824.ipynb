{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "EL dataset puede descargarse desde acá https://www.kaggle.com/datasets/imsparsh/flowers-dataset?resource=download"
      ],
      "metadata": {
        "id": "qa5JUFjIP14R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# ID del archivo de Google Drive (extraído de la URL)\n",
        "file_id = \"15dU4qL6J2CS9iAp36JxBDZOAI7pH6y0m\"\n",
        "# URL de descarga directa\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "# Nombre del archivo a guardar\n",
        "filename = \"archive.zip\"\n",
        "\n",
        "# Descargar el archivo\n",
        "gdown.download(url, filename, quiet=False)\n",
        "\n",
        "print(f\"Archivo descargado: {filename}\")\n"
      ],
      "metadata": {
        "id": "zo3aFbvUMyYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca9fc6b-bbd4-41ba-a87d-2d0a4bcae1ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=15dU4qL6J2CS9iAp36JxBDZOAI7pH6y0m\n",
            "From (redirected): https://drive.google.com/uc?id=15dU4qL6J2CS9iAp36JxBDZOAI7pH6y0m&confirm=t&uuid=2ea782e3-237a-4ee3-98cf-13c842854131\n",
            "To: /content/archive.zip\n",
            "100%|██████████| 215M/215M [00:13<00:00, 16.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo descargado: archive.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Nombre del archivo descargado\n",
        "filename = \"archive.zip\"\n",
        "\n",
        "# Ruta donde se descomprimirá el contenido\n",
        "extract_path = \"./flowers_dataset\"\n",
        "\n",
        "# Crear el directorio si no existe\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Descomprimir el archivo\n",
        "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Archivo descomprimido en: {extract_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9_dPfDzOYS2",
        "outputId": "98a891c2-c4df-4d25-ff34-90e25113a027"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo descomprimido en: ./flowers_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Configuración de parámetros\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Ruta del dataset\n",
        "data_dir = './flowers_dataset'\n",
        "\n",
        "# Transformaciones para el dataset de entrenamiento\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Cargar dataset de entrenamiento\n",
        "train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'train'), transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "# Definir el modelo ResNet-18 sin pesos preentrenados\n",
        "model = models.resnet18(weights=None)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, len(train_dataset.classes))  # Ajustar la capa final\n",
        "\n",
        "# Mover el modelo a GPU si está disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Definir la función de pérdida y el optimizador\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "start_time = time.time()  # Tiempo de inicio\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    epoch_start_time = time.time()  # Tiempo de inicio de la época\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update running loss\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    epoch_end_time = time.time()  # Tiempo de fin de la época\n",
        "    epoch_duration = epoch_end_time - epoch_start_time\n",
        "    avg_epoch_duration = (epoch_end_time - start_time) / (epoch + 1)\n",
        "    remaining_time = avg_epoch_duration * (num_epochs - (epoch + 1))\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "    print(f'Epoch Time: {epoch_duration:.2f}s, Estimated Time Remaining: {remaining_time:.2f}s')\n",
        "\n",
        "print('Entrenamiento completado.')\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "torch.save(model.state_dict(), 'resnet18_flower_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdW1lUBaO_Xr",
        "outputId": "b4506310-d89a-47db-eec0-b7fad59e9e7f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3321, Accuracy: 0.4421\n",
            "Epoch Time: 5.02s, Estimated Time Remaining: 45.22s\n",
            "Epoch 2/10, Loss: 1.0473, Accuracy: 0.5863\n",
            "Epoch Time: 3.31s, Estimated Time Remaining: 33.34s\n",
            "Epoch 3/10, Loss: 0.9385, Accuracy: 0.6351\n",
            "Epoch Time: 3.27s, Estimated Time Remaining: 27.07s\n",
            "Epoch 4/10, Loss: 0.8699, Accuracy: 0.6650\n",
            "Epoch Time: 3.70s, Estimated Time Remaining: 22.96s\n",
            "Epoch 5/10, Loss: 0.8025, Accuracy: 0.6908\n",
            "Epoch Time: 3.50s, Estimated Time Remaining: 18.81s\n",
            "Epoch 6/10, Loss: 0.7590, Accuracy: 0.6992\n",
            "Epoch Time: 3.40s, Estimated Time Remaining: 14.81s\n",
            "Epoch 7/10, Loss: 0.7001, Accuracy: 0.7353\n",
            "Epoch Time: 3.42s, Estimated Time Remaining: 10.98s\n",
            "Epoch 8/10, Loss: 0.6829, Accuracy: 0.7393\n",
            "Epoch Time: 3.44s, Estimated Time Remaining: 7.27s\n",
            "Epoch 9/10, Loss: 0.6374, Accuracy: 0.7600\n",
            "Epoch Time: 3.37s, Estimated Time Remaining: 3.60s\n",
            "Epoch 10/10, Loss: 0.5714, Accuracy: 0.7848\n",
            "Epoch Time: 3.32s, Estimated Time Remaining: 0.00s\n",
            "Entrenamiento completado.\n"
          ]
        }
      ]
    }
  ]
}